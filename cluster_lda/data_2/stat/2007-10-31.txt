0710.5805	stat.AP	Estimating exposure response functions using ambient pollution concentrations	This paper presents an approach to estimating the health effects of an environmental hazard . The approach is general in nature , but is applied here to the case of air pollution . It uses a computer model involving ambient pollution and temperature inputs , to simulate the exposures experienced by individuals in an urban area , whilst incorporating the mechanisms that determine exposures . The output from the model comprises a set of daily exposures for a sample of individuals from the population of interest . These daily exposures are approximated by parametric distributions , so that the predictive exposure distribution of a randomly selected individual can be generated . These distributions are then incorporated into a hierarchical Bayesian framework ( with inference using Markov Chain Monte Carlo simulation ) in order to examine the relationship between short-term changes in exposures and health outcomes , whilst making allowance for long-term trends , seasonality , the effect of potential confounders and the possibility of ecological bias . The paper applies this approach to particulate pollution ( PM $ _ { 10 } $ ) and respiratory mortality counts for seniors in greater London ( $ \geq $ 65 years ) during 1997 . Within this substantive epidemiological study , the effects on health of ambient concentrations and ( estimated ) personal exposures are compared .
0710.5837	stat.ME stat.AP stat.CO	On estimating covariances between many assets with histories of highly variable length	Quantitative portfolio allocation requires the accurate and tractable estimation of covariances between a large number of assets , whose histories can greatly vary in length . Such data are said to follow a monotone missingness pattern , under which the likelihood has a convenient factorization . Upon further assuming that asset returns are multivariate normally distributed , with histories at least as long as the total asset count , maximum likelihood ( ML ) estimates are easily obtained by performing repeated ordinary least squares ( OLS ) regressions , one for each asset . Things get more interesting when there are more assets than historical returns . OLS becomes unstable due to rank -- deficient design matrices , which is called a `` big p small n '' problem . We explore remedies that involve making a change of basis , as in principal components or partial least squares regression , or by applying shrinkage methods like ridge regression or the lasso . This enables the estimation of covariances between large sets of assets with histories of essentially arbitrary length , and offers improvements in accuracy and interpretation . We further extend the method by showing how external factors can be incorporated . This allows for the adaptive use of factors without the restrictive assumptions common in factor models . Our methods are demonstrated on randomly generated data , and then benchmarked by the performance of balanced portfolios using real historical financial returns . An accompanying R package called monomvn , containing code implementing the estimators described herein , has been made freely available on CRAN .
0710.5838	stat.ME	2-level fractional factorial designs which are the union of non trivial regular designs	Every fraction is a union of points , which are trivial regular fractions . To characterize non trivial decomposition , we derive a condition for the inclusion of a regular fraction as follows . Let $ F = \sum_\alpha b_\alpha X^\alpha $ be the indicator polynomial of a generic fraction , see Fontana et al , JSPI 2000 , 149-172 . Regular fractions are characterized by $ R = \frac 1l \sum_ { \alpha \in \mathcal L } e_\alpha X^\alpha $ , where $ \alpha \mapsto e_\alpha $ is an group homeomorphism from $ \mathcal L \subset \mathbb Z_2^d $ into $ \ { -1 , +1\ } $ . The regular $ R $ is a subset of the fraction $ F $ if $ FR = R $ , which in turn is equivalent to $ \sum_t F ( t ) R ( t ) = \sum_t R ( t ) $ . If $ \mathcal H = \ { \alpha_1 > ... \alpha_k\ } $ is a generating set of $ \mathcal L $ , and $ R = \frac1 { 2^k } ( 1 + e_1X^ { \alpha_1 } ) ... ( 1 + e_kX^ { \alpha_k } ) $ , $ e_j = \pm 1 $ , $ j=1 ... k $ , the inclusion condition in term of the $ b_\alpha $ 's is % \begin { equation } b_0 + e_1 b_ { \alpha_1 } + > ... + e_1 ... e_k b_ { \alpha_1 + ... + \alpha_k } = 1 . \tag { * } \end { equation } % The last part of the paper will discuss some examples to investigate the practical applicability of the previous condition ( * ) . This paper is an offspring of the Alcotra 158 EU research contract on the planning of sequential designs for sample surveys in tourism statistics .
0710.5896	stat.ML math.ST stat.TH	Supervised Machine Learning with a Novel Pointwise Density Estimator	This article proposes a novel density estimation based algorithm for carrying out supervised machine learning . The proposed algorithm features O ( n ) time complexity for generating a classifier , where n is the number of sampling instances in the training dataset . This feature is highly desirable in contemporary applications that involve large and still growing databases . In comparison with the kernel density estimation based approaches , the mathe-matical fundamental behind the proposed algorithm is not based on the assump-tion that the number of training instances approaches infinite . As a result , a classifier generated with the proposed algorithm may deliver higher prediction accuracy than the kernel density estimation based classifier in some cases .
