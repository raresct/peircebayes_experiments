0712.3735	stat.ME math.ST stat.TH	Nonparametric estimation for a stochastic volatility model	Consider discrete time observations ( X_ { \ell\delta } ) _ { 1\leq \ell \leq n+1 } $ of the process $ X $ satisfying $ dX_t= \sqrt { V_t } dB_t $ , with $ V_t $ a one-dimensional positive diffusion process independent of the Brownian motion $ B $ . For both the drift and the diffusion coefficient of the unobserved diffusion $ V $ , we propose nonparametric least square estimators , and provide bounds for theirrisk . Estimators are chosen among a collection of functions belonging to a finite dimensional space whose dimension is selected by a data driven procedure . Implementation on simulated data illustrates how the method works .
0712.3744	stat.CO math.OC	Convergence properties of the expected improvement algorithm	This paper has been withdrawn from the arXiv . It is now published by Elsevier in the Journal of Statistical Planning and Inference , under the modified title '' Convergence properties of the expected improvement algorithm with fixed mean and covariance functions '' . See http : //dx.doi.org/10.1016/j.jspi.2010.04.018 An author-generated post-print version is available from the HAL repository of SUPELEC at http : //hal-supelec.archives-ouvertes.fr/hal-00217562 Abstract : `` This paper deals with the convergence of the expected improvement algorithm , a popular global optimization algorithm based on a Gaussian process model of the function to be optimized . The first result is that under some mild hypotheses on the covariance function k of the Gaussian process , the expected improvement algorithm produces a dense sequence of evaluation points in the search domain , when the function to be optimized is in the reproducing kernel Hilbert space generated by k. The second result states that the density property also holds for P-almost all continuous functions , where P is the ( prior ) probability distribution induced by the Gaussian process . ''
