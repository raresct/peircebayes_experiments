0710.4228	stat.ME stat.CO	Retrospective Markov chain Monte Carlo methods for Dirichlet process hierarchical model	Inference for Dirichlet process hierarchical models is typically performed using Markov chain Monte Carlo methods , which can be roughly categorised into marginal and conditional methods . The former integrate out analytically the infinite-dimensional component of the hierarchical model and sample from the marginal distribution of the remaining variables using the Gibbs sampler . Conditional methods impute the Dirichlet process and update it as a component of the Gibbs sampler . Since this requires imputation of an infinite-dimensional process , implementation of the conditional method has relied on finite approximations . In this paper we show how to avoid such approximations by designing two novel Markov chain Monte Carlo algorithms which sample from the exact posterior distribution of quantities of interest . The approximations are avoided by the new technique of retrospective sampling . We also show how the algorithms can obtain samples from functionals of the Dirichlet process . The marginal and the conditional methods are compared and a careful simulation study is included , which involves a non-conjugate model , different datasets and prior specifications .
0710.4234	stat.ME stat.CO	Stability of the Gibbs Sampler for Bayesian Hierarchical Models	We characterise the convergence of the Gibbs sampler which samples from the joint posterior distribution of parameters and missing data in hierarchical linear models with arbitrary symmetric error distributions . We show that the convergence can be uniform , geometric or sub-geometric depending on the relative tail behaviour of the error distributions , and on the parametrisation chosen . Our theory is applied to characterise the convergence of the Gibbs sampler on latent Gaussian process models . We indicate how the theoretical framework we introduce will be useful in analyzing more complex models .
0710.4242	stat.CO	Adaptive Importance Sampling in General Mixture Classes	In this paper , we propose an adaptive algorithm that iteratively updates both the weights and component parameters of a mixture importance sampling density so as to optimise the importance sampling performances , as measured by an entropy criterion . The method is shown to be applicable to a wide class of importance sampling densities , which includes in particular mixtures of multivariate Student t distributions . The performances of the proposed scheme are studied on both artificial and real examples , highlighting in particular the benefit of a novel Rao-Blackwellisation device which can be easily incorporated in the updating scheme .
0710.4245	stat.ME stat.CO	Particle Filters for Partially Observed Diffusions	In this paper we introduce a novel particle filter scheme for a class of partially-observed multivariate diffusions . % continuous-time dynamic models where the % signal is given by a multivariate diffusion process . We consider a variety of observation schemes , including diffusion observed with error , observation of a subset of the components of the multivariate diffusion and arrival times of a Poisson process whose intensity is a known function of the diffusion ( Cox process ) . Unlike currently available methods , our particle filters do not require approximations of the transition and/or the observation density using time-discretisations . Instead , they build on recent methodology for the exact simulation of the diffusion process and the unbiased estimation of the transition density as described in \cite { besk : papa : robe : fear:2006 } . % In particular , w We introduce the Generalised Poisson Estimator , which generalises the Poisson Estimator of \cite { besk : papa : robe : fear:2006 } . % Thus , our filters avoid the systematic biases caused by % time-discretisations and they have significant computational % advantages over alternative continuous-time filters . These % advantages are supported theoretically by a A central limit theorem is given for our particle filter scheme .
