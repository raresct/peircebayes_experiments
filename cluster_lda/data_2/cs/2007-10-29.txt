0710.5333	cs.DB	Neutrosophic Relational Data Model	In this paper , we present a generalization of the relational data model based on interval neutrosophic set . Our data model is capable of manipulating incomplete as well as inconsistent information . Fuzzy relation or intuitionistic fuzzy relation can only handle incomplete information . Associated with each relation are two membership functions one is called truth-membership function T which keeps track of the extent to which we believe the tuple is in the relation , another is called falsity-membership function F which keeps track of the extent to which we believe that it is not in the relation . A neutrosophic relation is inconsistent if there exists one tuple a such that T ( a ) + F ( a ) > 1 . In order to handle inconsistent situation , we propose an operator called `` split '' to transform inconsistent neutrosophic relations into pseudo-consistent neutrosophic relations and do the set-theoretic and relation-theoretic operations on them and finally use another operator called `` combine '' to transform the result back to neutrosophic relation . For this data model , we define algebraic operators that are generalizations of the usual operators such as intersection , union , selection , join on fuzzy relations . Our data model can underlie any database and knowledge-base management system that deals with incomplete and inconsistent information .
0710.5338	cs.DM cs.CC	Weighted Random Popular Matchings	For a set A of n applicants and a set I of m items , we consider a problem of computing a matching of applicants to items , i.e. , a function M mapping A to I ; here we assume that each applicant $ x \in A $ provides a preference list on items in I . We say that an applicant $ x \in A $ prefers an item p than an item q if p is located at a higher position than q in its preference list , and we say that x prefers a matching M over a matching M ' if x prefers M ( x ) over M ' ( x ) . For a given matching problem A , I , and preference lists , we say that M is more popular than M ' if the number of applicants preferring M over M ' is larger than that of applicants preferring M ' over M , and M is called a popular matching if there is no other matching that is more popular than M. Here we consider the situation that A is partitioned into $ A_ { 1 } , A_ { 2 } , ... , A_ { k } $ , and that each $ A_ { i } $ is assigned a weight $ w_ { i } > 0 $ such that w_ { 1 } > w_ { 2 } > ... > w_ { k } > 0 $ . For such a matching problem , we say that M is more popular than M ' if the total weight of applicants preferring M over M ' is larger than that of applicants preferring M ' over M , and we call M an k-weighted popular matching if there is no other matching that is more popular than M. In this paper , we analyze the 2-weighted matching problem , and we show that ( lower bound ) if $ m/n^ { 4/3 } =o ( 1 ) $ , then a random instance of the 2-weighted matching problem with $ w_ { 1 } \geq 2w_ { 2 } $ has a 2-weighted popular matching with probability o ( 1 ) ; and ( upper bound ) if $ n^ { 4/3 } /m = o ( 1 ) $ , then a random instance of the 2-weighted matching problem with $ w_ { 1 } \geq 2w_ { 2 } $ has a 2-weighted popular matching with probability 1-o ( 1 ) .
0710.5340	cs.IT cs.NI math.IT	Bounds on the Network Coding Capacity for Wireless Random Networks	Recently , it has been shown that the max flow capacity can be achieved in a multicast network using network coding . In this paper , we propose and analyze a more realistic model for wireless random networks . We prove that the capacity of network coding for this model is concentrated around the expected value of its minimum cut . Furthermore , we establish upper and lower bounds for wireless nodes using Chernoff bound . Our experiments show that our theoretical predictions are well matched by simulation results .
0710.5348	cs.DC	Towards Grid Monitoring and deployment in Jade , using ProActive	This document describes our current effort to gridify Jade , a java-based environment for the autonomic management of clustered J2EE application servers , developed in the INRIA SARDES research team . Towards this objective , we use the java ProActive grid technology . We first present some of the challenges to turn such an autonomic management system initially dedicated to distributed applications running on clusters of machines , into one that can provide self-management capabilities to large-scale systems , i.e . deployed on grid infrastructures . This leads us to a brief state of the art on grid monitoring systems . Then , we recall the architecture of Jade , and consequently propose to reorganize it in a potentially more scalable way . Practical experiments pertain to the use of the grid deployment feature offered by ProActive to easily conduct the deployment of the Jade system or its revised version on any sort of grid .
0710.5376	cs.IT math.IT	Broadcasting Correlated Gaussians	We consider the transmission of a memoryless bivariate Gaussian source over an average-power-constrained one-to-two Gaussian broadcast channel . The transmitter observes the source and describes it to the two receivers by means of an average-power-constrained signal . Each receiver observes the transmitted signal corrupted by a different additive white Gaussian noise and wishes to estimate the source component intended for it . That is , Receiver~1 wishes to estimate the first source component and Receiver~2 wishes to estimate the second source component . Our interest is in the pairs of expected squared-error distortions that are simultaneously achievable at the two receivers . We prove that an uncoded transmission scheme that sends a linear combination of the source components achieves the optimal power-versus-distortion trade-off whenever the signal-to-noise ratio is below a certain threshold . The threshold is a function of the source correlation and the distortion at the receiver with the weaker noise .
0710.5382	cs.CL	Some Reflections on the Task of Content Determination in the Context of Multi-Document Summarization of Evolving Events	Despite its importance , the task of summarizing evolving events has received small attention by researchers in the field of multi-document summariztion . In a previous paper ( Afantenos et al . 2007 ) we have presented a methodology for the automatic summarization of documents , emitted by multiple sources , which describe the evolution of an event . At the heart of this methodology lies the identification of similarities and differences between the various documents , in two axes : the synchronic and the diachronic . This is achieved by the introduction of the notion of Synchronic and Diachronic Relations . Those relations connect the messages that are found in the documents , resulting thus in a graph which we call grid . Although the creation of the grid completes the Document Planning phase of a typical NLG architecture , it can be the case that the number of messages contained in a grid is very large , exceeding thus the required compression rate . In this paper we provide some initial thoughts on a probabilistic model which can be applied at the Content Determination stage , and which tries to alleviate this problem .
0710.5425	cs.CR	Fuzzy Private Matching ( Extended Abstract )	In the private matching problem , a client and a server each hold a set of $ n $ input elements . The client wants to privately compute the intersection of these two sets : he learns which elements he has in common with the server ( and nothing more ) , while the server gains no information at all . In certain applications it would be useful to have a private matching protocol that reports a match even if two elements are only similar instead of equal . Such a private matching protocol is called \emph { fuzzy } , and is useful , for instance , when elements may be inaccurate or corrupted by errors . We consider the fuzzy private matching problem , in a semi-honest environment . Elements are similar if they match on $ t $ out of $ T $ attributes . First we show that the original solution proposed by Freedman et al . is incorrect . Subsequently we present two fuzzy private matching protocols . The first , simple , protocol has bit message complexity $ O ( n \binom { T } { t } ( T \log { |D| } +k ) ) $ . The second , improved , protocol has a much better bit message complexity of $ O ( n T ( \log { |D| } +k ) ) $ , but here the client incurs a O ( n ) factor time complexity . Additionally , we present protocols based on the computation of the Hamming distance and on oblivious transfer , that have different , sometimes more efficient , performance characteristics .
0710.5501	cs.IT cs.AI math.IT	Discriminated Belief Propagation	Near optimal decoding of good error control codes is generally a difficult task . However , for a certain type of ( sufficiently ) good codes an efficient decoding algorithm with near optimal performance exists . These codes are defined via a combination of constituent codes with low complexity trellis representations . Their decoding algorithm is an instance of ( loopy ) belief propagation and is based on an iterative transfer of constituent beliefs . The beliefs are thereby given by the symbol probabilities computed in the constituent trellises . Even though weak constituent codes are employed close to optimal performance is obtained , i.e. , the encoder/decoder pair ( almost ) achieves the information theoretic capacity . However , ( loopy ) belief propagation only performs well for a rather specific set of codes , which limits its applicability . In this paper a generalisation of iterative decoding is presented . It is proposed to transfer more values than just the constituent beliefs . This is achieved by the transfer of beliefs obtained by independently investigating parts of the code space . This leads to the concept of discriminators , which are used to improve the decoder resolution within certain areas and defines discriminated symbol beliefs . It is shown that these beliefs approximate the overall symbol probabilities . This leads to an iteration rule that ( below channel capacity ) typically only admits the solution of the overall decoding problem . Via a Gauss approximation a low complexity version of this algorithm is derived . Moreover , the approach may then be applied to a wide range of channel maps without significant complexity increase .
0710.5512	cs.CE	Risk Minimization and Optimal Derivative Design in a Principal Agent Game	We consider the problem of Adverse Selection and optimal derivative design within a Principal-Agent framework . The principal 's income is exposed to non-hedgeable risk factors arising , for instance , from weather or climate phenomena . She evaluates her risk using a coherent and law invariant risk measure and tries minimize her exposure by selling derivative securities on her income to individual agents . The agents have mean-variance preferences with heterogeneous risk aversion coefficients . An agent 's degree of risk aversion is private information and hidden to the principal who only knows the overall distribution . We show that the principal 's risk minimization problem has a solution and illustrate the effects of risk transfer on her income by means of two specific examples . Our model extends earlier work of Barrieu and El Karoui ( 2005 ) and Carlier , Ekeland and Touzi ( 2007 ) .
0710.5547	cs.CV cs.DS	Code Similarity on High Level Programs	This paper presents a new approach for code similarity on High Level programs . Our technique is based on Fast Dynamic Time Warping , that builds a warp path or points relation with local restrictions . The source code is represented into Time Series using the operators inside programming languages that makes possible the comparison . This makes possible subsequence detection that represent similar code instructions . In contrast with other code similarity algorithms , we do not make features extraction . The experiments show that two source codes are similar when their respective Time Series are similar .
