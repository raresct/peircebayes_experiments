0704.0301	cs.CC	Differential Recursion and Differentially Algebraic Functions	Moore introduced a class of real-valued `` recursive '' functions by analogy with Kleene 's formulation of the standard recursive functions . While his concise definition inspired a new line of research on analog computation , it contains some technical inaccuracies . Focusing on his `` primitive recursive '' functions , we pin down what is problematic and discuss possible attempts to remove the ambiguity regarding the behavior of the differential recursion operator on partial functions . It turns out that in any case the purported relation to differentially algebraic functions , and hence to Shannon 's model of analog computation , fails .
0704.0361	cs.IT math.IT	Pseudo-random Puncturing : A Technique to Lower the Error Floor of Turbo Codes	It has been observed that particular rate-1/2 partially systematic parallel concatenated convolutional codes ( PCCCs ) can achieve a lower error floor than that of their rate-1/3 parent codes . Nevertheless , good puncturing patterns can only be identified by means of an exhaustive search , whilst convergence towards low bit error probabilities can be problematic when the systematic output of a rate-1/2 partially systematic PCCC is heavily punctured . In this paper , we present and study a family of rate-1/2 partially systematic PCCCs , which we call pseudo-randomly punctured codes . We evaluate their bit error rate performance and we show that they always yield a lower error floor than that of their rate-1/3 parent codes . Furthermore , we compare analytic results to simulations and we demonstrate that their performance converges towards the error floor region , owning to the moderate puncturing of their systematic output . Consequently , we propose pseudo-random puncturing as a means of improving the bandwidth efficiency of a PCCC and simultaneously lowering its error floor .
0704.0468	cs.CC cs.DS	Inapproximability of Maximum Weighted Edge Biclique and Its Applications	Given a bipartite graph $ G = ( V_1 , V_2 , E ) $ where edges take on { \it both } positive and negative weights from set $ \mathcal { S } $ , the { \it maximum weighted edge biclique } problem , or $ \mathcal { S } $ -MWEB for short , asks to find a bipartite subgraph whose sum of edge weights is maximized . This problem has various applications in bioinformatics , machine learning and databases and its ( in ) approximability remains open . In this paper , we show that for a wide range of choices of $ \mathcal { S } $ , specifically when $ | \frac { \min\mathcal { S } } { \max \mathcal { S } } | \in \Omega ( \eta^ { \delta-1/2 } ) \cap O ( \eta^ { 1/2-\delta } ) $ ( where $ \eta = \max\ { |V_1| , |V_2|\ } $ , and $ \delta \in ( 0,1/2 ] $ ) , no polynomial time algorithm can approximate $ \mathcal { S } $ -MWEB within a factor of $ n^ { \epsilon } $ for some $ \epsilon > 0 $ unless $ \mathsf { RP = NP } $ . This hardness result gives justification of the heuristic approaches adopted for various applied problems in the aforementioned areas , and indicates that good approximation algorithms are unlikely to exist . Specifically , we give two applications by showing that : 1 ) finding statistically significant biclusters in the SAMBA model , proposed in \cite { Tan02 } for the analysis of microarray data , is $ n^ { \epsilon } $ -inapproximable ; and 2 ) no polynomial time algorithm exists for the Minimum Description Length with Holes problem \cite { Bu05 } unless $ \mathsf { RP=NP } $ .
