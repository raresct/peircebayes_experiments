0705.2765	cs.LG cs.AI	On the monotonization of the training set	We consider the problem of minimal correction of the training set to make it consistent with monotonic constraints . This problem arises during analysis of data sets via techniques that require monotone data . We show that this problem is NP-hard in general and is equivalent to finding a maximal independent set in special orgraphs . Practically important cases of that problem considered in detail . These are the cases when a partial order given on the replies set is a total order or has a dimension 2 . We show that the second case can be reduced to maximization of a quadratic convex function on a convex set . For this case we construct an approximate polynomial algorithm based on convex optimization .
0705.2786	cs.OS cs.CR	Virtualization : A double-edged sword	Virtualization became recently a hot topic once again , after being dormant for more than twenty years . In the meantime , it has been almost forgotten , that virtual machines are not so perfect isolating environments as it seems , when looking at the principles . These lessons were already learnt earlier when the first virtualized systems have been exposed to real life usage . Contemporary virtualization software enables instant creation and destruction of virtual machines on a host , live migration from one host to another , execution history manipulation , etc . These features are very useful in practice , but also causing headaches among security specialists , especially in current hostile network environments . In the present contribution we discuss the principles , potential benefits and risks of virtualization in a deja vu perspective , related to previous experiences with virtualization in the mainframe era .
0705.2787	cs.DB	Worst-Case Background Knowledge for Privacy-Preserving Data Publishing	Recent work has shown the necessity of considering an attacker 's background knowledge when reasoning about privacy in data publishing . However , in practice , the data publisher does not know what background knowledge the attacker possesses . Thus , it is important to consider the worst-case . In this paper , we initiate a formal study of worst-case background knowledge . We propose a language that can express any background knowledge about the data . We provide a polynomial time algorithm to measure the amount of disclosure of sensitive information in the worst case , given that the attacker has at most a specified number of pieces of information in this language . We also provide a method to efficiently sanitize the data so that the amount of disclosure in the worst case is less than a specified threshold .
