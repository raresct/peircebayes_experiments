0712.1875	cs.IT math.IT math.LO math.PR math.RA quant-ph	Critique du rapport signal \`a bruit en th\'eorie de l'information -- A critical appraisal of the signal to noise ratio in information theory	The signal to noise ratio , which plays such an important role in information theory , is shown to become pointless in digital communications where - symbols are modulating carriers , which are solutions of linear differential equations with polynomial coefficients , - demodulations is achieved thanks to new algebraic estimation techniques . Operational calculus , differential algebra and nonstandard analysis are the main mathematical tools .
0712.1878	cs.CV	Hierarchy construction schemes within the Scale set framework	Segmentation algorithms based on an energy minimisation framework often depend on a scale parameter which balances a fit to data and a regularising term . Irregular pyramids are defined as a stack of graphs successively reduced . Within this framework , the scale is often defined implicitly as the height in the pyramid . However , each level of an irregular pyramid can not usually be readily associated to the global optimum of an energy or a global criterion on the base level graph . This last drawback is addressed by the scale set framework designed by Guigues . The methods designed by this author allow to build a hierarchy and to design cuts within this hierarchy which globally minimise an energy . This paper studies the influence of the construction scheme of the initial hierarchy on the resulting optimal cuts . We propose one sequential and one parallel method with two variations within both . Our sequential methods provide partitions near the global optima while parallel methods require less execution times than the sequential method of Guigues even on sequential machines .
0712.1916	cs.DL	Ranking forestry journals using the h-index	An expert ranking of forestry journals was compared with journal impact factors and h-indices computed from the ISI Web of Science and internet-based data . Citations reported by Google Scholar appear to offer the most efficient way to rank all journals objectively , in a manner consistent with other indicators . This h-index exhibited a high correlation with the journal impact factor ( r=0.92 ) , but is not confined to journals selected by any particular commercial provider . A ranking of 180 forestry journals is presented , on the basis of this index .
0712.1928	cs.NI cond-mat.other	Distribution of Edge Load in Scale-free Trees	Node betweenness has been studied recently by a number of authors , but until now less attention has been paid to edge betweenness . In this paper , we present an exact analytic study of edge betweenness in evolving scale-free and non-scale-free trees . We aim at the probability distribution of edge betweenness under the condition that a local property , the in-degree of the `` younger '' node of a randomly selected edge , is known . En route to the conditional distribution of edge betweenness the exact joint distribution of cluster size and in-degree , and its one dimensional marginal distributions have been presented in the paper as well . From the derived probability distributions the expectation values of different quantities have been calculated . Our results provide an exact solution not only for infinite , but for finite networks as well .
0712.1959	cs.CG cs.DS	Delaunay Edge Flips in Dense Surface Triangulations	Delaunay flip is an elegant , simple tool to convert a triangulation of a point set to its Delaunay triangulation . The technique has been researched extensively for full dimensional triangulations of point sets . However , an important case of triangulations which are not full dimensional is surface triangulations in three dimensions . In this paper we address the question of converting a surface triangulation to a subcomplex of the Delaunay triangulation with edge flips . We show that the surface triangulations which closely approximate a smooth surface with uniform density can be transformed to a Delaunay triangulation with a simple edge flip algorithm . The condition on uniformity becomes less stringent with increasing density of the triangulation . If the condition is dropped completely , the flip algorithm still terminates although the output surface triangulation becomes `` almost Delaunay '' instead of exactly Delaunay .
0712.1987	cs.IT math.IT	A New Outer Bound and the Noisy-Interference Sum-Rate Capacity for Gaussian Interference Channels	A new outer bound on the capacity region of Gaussian interference channels is developed . The bound combines and improves existing genie-aided methods and is shown to give the sum-rate capacity for noisy interference as defined in this paper . Specifically , it is shown that if the channel coefficients and power constraints satisfy a simple condition then single-user detection at each receiver is sum-rate optimal , i.e. , treating the interference as noise incurs no loss in performance . This is the first concrete ( finite signal-to-noise ratio ) capacity result for the Gaussian interference channel with weak to moderate interference . Furthermore , for certain mixed ( weak and strong ) interference scenarios , the new outer bounds give a corner point of the capacity region .
0712.1994	cs.OH	Knowledge Engineering Technique for Cluster Development	After the concept of industry cluster was tangibly applied in many countries , SMEs trended to link to each other to maintain their competitiveness in the market . The major key success factors of the cluster are knowledge sharing and collaboration between partners . This knowledge is collected in form of tacit and explicit knowledge from experts and institutions within the cluster . The objective of this study is about enhancing the industry cluster with knowledge management by using knowledge engineering which is one of the most important method for managing knowledge . This work analyzed three well known knowledge engineering methods , i.e . MOKA , SPEDE and CommonKADS , and compares the capability to be implemented in the cluster context . Then , we selected one method and proposed the adapted methodology . At the end of this paper , we validated and demonstrated the proposed methodology with some primary result by using case study of handicraft cluster in Thailand .
0712.1996	cs.LO cs.CC cs.DB	A case study of the difficulty of quantifier elimination in constraint databases : the alibi query in moving object databases	In the constraint database model , spatial and spatio-temporal data are stored by boolean combinations of polynomial equalities and inequalities over the real numbers . The relational calculus augmented with polynomial constraints is the standard first-order query language for constraint databases . Although the expressive power of this query language has been studied extensively , the difficulty of the efficient evaluation of queries , usually involving some form of quantifier elimination , has received considerably less attention . The inefficiency of existing quantifier-elimination software and the intrinsic difficulty of quantifier elimination have proven to be a bottle-neck for for real-world implementations of constraint database systems . In this paper , we focus on a particular query , called the \emph { alibi query } , that asks whether two moving objects whose positions are known at certain moments in time , could have possibly met , given certain speed constraints . This query can be seen as a constraint database query and its evaluation relies on the elimination of a block of three existential quantifiers . Implementations of general purpose elimination algorithms are in the specific case , for practical purposes , too slow in answering the alibi query and fail completely in the parametric case . The main contribution of this paper is an analytical solution to the parametric alibi query , which can be used to answer this query in the specific case in constant time . We also give an analytic solution to the alibi query at a fixed moment in time . The solutions we propose are based on geometric argumentation and they illustrate the fact that some practical problems require creative solutions , where at least in theory , existing systems could provide a solution .
0712.2054	cs.NI	Distributed Fair Scheduling Using Variable Transmission Lengths in Carrier-Sensing-based Wireless Networks	The fairness of IEEE 802.11 wireless networks ( including Wireless LAN and Ad-hoc networks ) is hard to predict and control because of the randomness and complexity of the MAC contentions and dynamics . Moreover , asymmetric channel conditions such as those caused by capture and channel errors often lead to severe unfairness among stations . In this paper we propose a novel distributed scheduling algorithm that we call VLS , for `` { \em variable-length scheduling } '' , that provides weighted fairness to all stations despite the imperfections of the MAC layer and physical channels . Distinct features of VLS include the use of variable transmission lengths based on distributed observations , compatibility with 802.11 's contention window algorithm , opportunistic scheduling to achieve high throughput in time-varying wireless environments , and flexibility and ease of implementation . Also , VLS makes the throughput of each station more smooth , which is appealing to real-time applications such as video and voice . Although the paper mostly assumes 802.11 protocol , the idea generally applies to wireless networks based on CSMA ( Carrier Sensing Multiple Access ) .
0712.2063	cs.IR	An axiomatic approach to intrinsic dimension of a dataset	We perform a deeper analysis of an axiomatic approach to the concept of intrinsic dimension of a dataset proposed by us in the IJCNN'07 paper ( arXiv : cs/0703125 ) . The main features of our approach are that a high intrinsic dimension of a dataset reflects the presence of the curse of dimensionality ( in a certain mathematically precise sense ) , and that dimension of a discrete i.i.d . sample of a low-dimensional manifold is , with high probability , close to that of the manifold . At the same time , the intrinsic dimension of a sample is easily corrupted by moderate high-dimensional noise ( of the same amplitude as the size of the manifold ) and suffers from prohibitevely high computational complexity ( computing it is an $ NP $ -complete problem ) . We outline a possible way to overcome these difficulties .
0712.2083	cs.NI	VoIP over Multiple IEEE 802.11 Wireless LANs	Prior work indicates that 802.11 is extremely inefficient for VoIP transport . Only 12 and 60 VoIP sessions can be supported in an 802.11b and an 802.11g WLAN , respectively . This paper shows that the bad news does not stop there . When there are multiple WLANs in the vicinity of each other , the already-low VoIP capacity can be further eroded in a significant manner . For example , in a 5-by-5 , 25-cell multi-WLAN network , the VoIP capacities for 802.11b and 802.11g are only 1.63 and 10.34 sessions per AP , respectively . This paper investigates several solutions to improve the VoIP capacity . Based on a conflict graph model , we propose a clique-analytical call-admission scheme , which increases the VoIP capacity by 52 % and 37 % in 802.11b and 802.11g respectively . If all the three orthogonal frequency channels available in 11b and 11g are used , the capacity can be nearly tripled by the call-admission scheme . This paper also proposes for the first time the use of coarse-grained time-division multiple access ( CoTDMA ) in conjunction with the basic 802.11 CSMA to eliminate the performance-degrading exposed-node and hidden-node problems . We find that CoTDMA can further increase the VoIP capacity in the multi-WLAN scenario by an additional 35 % .
0712.2094	cs.CG	Hinged Dissections Exist	We prove that any finite collection of polygons of equal area has a common hinged dissection . That is , for any such collection of polygons there exists a chain of polygons hinged at vertices that can be folded in the plane continuously without self-intersection to form any polygon in the collection . This result settles the open problem about the existence of hinged dissections between pairs of polygons that goes back implicitly to 1864 and has been studied extensively in the past ten years . Our result generalizes and indeed builds upon the result from 1814 that polygons have common dissections ( without hinges ) . We also extend our common dissection result to edge-hinged dissections of solid 3D polyhedra that have a common ( unhinged ) dissection , as determined by Dehn 's 1900 solution to Hilbert 's Third Problem . Our proofs are constructive , giving explicit algorithms in all cases . For a constant number of planar polygons , both the number of pieces and running time required by our construction are pseudopolynomial . This bound is the best possible , even for unhinged dissections . Hinged dissections have possible applications to reconfigurable robotics , programmable matter , and nanomanufacturing .
