0711.3861	cs.DS	Approximation Algorithms for Restless Bandit Problems	The restless bandit problem is one of the most well-studied generalizations of the celebrated stochastic multi-armed bandit problem in decision theory . In its ultimate generality , the restless bandit problem is known to be PSPACE-Hard to approximate to any non-trivial factor , and little progress has been made despite its importance in modeling activity allocation under uncertainty . We consider a special case that we call Feedback MAB , where the reward obtained by playing each of n independent arms varies according to an underlying on/off Markov process whose exact state is only revealed when the arm is played . The goal is to design a policy for playing the arms in order to maximize the infinite horizon time average expected reward . This problem is also an instance of a Partially Observable Markov Decision Process ( POMDP ) , and is widely studied in wireless scheduling and unmanned aerial vehicle ( UAV ) routing . Unlike the stochastic MAB problem , the Feedback MAB problem does not admit to greedy index-based optimal policies . We develop a novel and general duality-based algorithmic technique that yields a surprisingly simple and intuitive 2+epsilon-approximate greedy policy to this problem . We then define a general sub-class of restless bandit problems that we term Monotone bandits , for which our policy is a 2-approximation . Our technique is robust enough to handle generalizations of these problems to incorporate various side-constraints such as blocking plays and switching costs . This technique is also of independent interest for other restless bandit problems . By presenting the first ( and efficient ) O ( 1 ) approximations for non-trivial instances of restless bandits as well as of POMDPs , our work initiates the study of approximation algorithms in both these contexts .
0711.3915	cs.IT cs.MA math.IT math.OC	Distributed Consensus Algorithms in Sensor Networks : Link Failures and Channel Noise	The paper studies average consensus with random topologies ( intermittent links ) \emph { and } noisy channels . Consensus with noise in the network links leads to the bias-variance dilemma -- running consensus for long reduces the bias of the final average estimate but increases its variance . We present two different compromises to this tradeoff : the $ \mathcal { A-ND } $ algorithm modifies conventional consensus by forcing the weights to satisfy a \emph { persistence } condition ( slowly decaying to zero ) ; and the $ \mathcal { A-NC } $ algorithm where the weights are constant but consensus is run for a fixed number of iterations $ \hat { \imath } $ , then it is restarted and rerun for a total of $ \hat { p } $ runs , and at the end averages the final states of the $ \hat { p } $ runs ( Monte Carlo averaging ) . We use controlled Markov processes and stochastic approximation arguments to prove almost sure convergence of $ \mathcal { A-ND } $ to the desired average ( asymptotic unbiasedness ) and compute explicitly the m.s.e . ( variance ) of the consensus limit . We show that $ \mathcal { A-ND } $ represents the best of both worlds -- low bias and low variance -- at the cost of a slow convergence rate ; rescaling the weights ...
0711.3926	cs.IT math.IT	Rateless codes for AVC models	The arbitrarily varying channel ( AVC ) is a channel model whose state is selected maliciously by an adversary . Fixed-blocklength coding assumes a worst-case bound on the adversary 's capabilities , which leads to pessimistic results . This paper defines a variable-length perspective on this problem , for which achievable rates are shown that depend on the realized actions of the adversary . Specifically , rateless codes are constructed which require a limited amount of common randomness . These codes are constructed for two kinds of AVC models . In the first the channel state can not depend on the channel input , and in the second it can . As a byproduct , the randomized coding capacity of the AVC with state depending on the transmitted codeword is found and shown to be achievable with a small amount of common randomness . The results for this model are proved using a randomized strategy based on list decoding .
0711.3935	cs.IT cs.NI math.IT	Coding for Network Coding	We consider communication over a noisy network under randomized linear network coding . Possible error mechanism include node- or link- failures , Byzantine behavior of nodes , or an over-estimate of the network min-cut . Building on the work of Koetter and Kschischang , we introduce a probabilistic model for errors . We compute the capacity of this channel and we define an error-correction scheme based on random sparse graphs and a low-complexity decoding algorithm . By optimizing over the code degree profile , we show that this construction achieves the channel capacity in complexity which is jointly quadratic in the number of coded information bits and sublogarithmic in the error probability .
