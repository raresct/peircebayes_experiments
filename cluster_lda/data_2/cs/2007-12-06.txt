0712.0932	cs.CV cs.AI cs.NE	Dimensionality Reduction and Reconstruction using Mirroring Neural Networks and Object Recognition based on Reduced Dimension Characteristic Vector	In this paper , we present a Mirroring Neural Network architecture to perform non-linear dimensionality reduction and Object Recognition using a reduced lowdimensional characteristic vector . In addition to dimensionality reduction , the network also reconstructs ( mirrors ) the original high-dimensional input vector from the reduced low-dimensional data . The Mirroring Neural Network architecture has more number of processing elements ( adalines ) in the outer layers and the least number of elements in the central layer to form a converging-diverging shape in its configuration . Since this network is able to reconstruct the original image from the output of the innermost layer ( which contains all the information about the input pattern ) , these outputs can be used as object signature to classify patterns . The network is trained to minimize the discrepancy between actual output and the input by back propagating the mean squared error from the output layer to the input layer . After successfully training the network , it can reduce the dimension of input vectors and mirror the patterns fed to it . The Mirroring Neural Network architecture gave very good results on various test patterns .
0712.0938	cs.LG cs.AI cs.NE	Automatic Pattern Classification by Unsupervised Learning Using Dimensionality Reduction of Data with Mirroring Neural Networks	This paper proposes an unsupervised learning technique by using Multi-layer Mirroring Neural Network and Forgy 's clustering algorithm . Multi-layer Mirroring Neural Network is a neural network that can be trained with generalized data inputs ( different categories of image patterns ) to perform non-linear dimensionality reduction and the resultant low-dimensional code is used for unsupervised pattern classification using Forgy 's algorithm . By adapting the non-linear activation function ( modified sigmoidal function ) and initializing the weights and bias terms to small random values , mirroring of the input pattern is initiated . In training , the weights and bias terms are changed in such a way that the input presented is reproduced at the output by back propagating the error . The mirroring neural network is capable of reducing the input vector to a great degree ( approximately 1/30th the original size ) and also able to reconstruct the input pattern at the output layer from this reduced code units . The feature set ( output of central hidden layer ) extracted from this network is fed to Forgy 's algorithm , which classify input data patterns into distinguishable classes . In the implementation of Forgy's algorithm , initial seed points are selected in such a way that they are distant enough to be perfectly grouped into different categories . Thus a new method of unsupervised learning is formulated and demonstrated in this paper . This method gave impressive results when applied to classification of different image patterns .
0712.0948	cs.AI cs.LO	A Common View on Strong , Uniform , and Other Notions of Equivalence in Answer-Set Programming	Logic programming under the answer-set semantics nowadays deals with numerous different notions of program equivalence . This is due to the fact that equivalence for substitution ( known as strong equivalence ) and ordinary equivalence are different concepts . The former holds , given programs P and Q , iff P can be faithfully replaced by Q within any context R , while the latter holds iff P and Q provide the same output , that is , they have the same answer sets . Notions in between strong and ordinary equivalence have been introduced as theoretical tools to compare incomplete programs and are defined by either restricting the syntactic structure of the considered context programs R or by bounding the set A of atoms allowed to occur in R ( relativized equivalence ) .For the latter approach , different A yield properly different equivalence notions , in general . For the former approach , however , it turned out that any `` reasonable '' syntactic restriction to R coincides with either ordinary , strong , or uniform equivalence . In this paper , we propose a parameterization for equivalence notions which takes care of both such kinds of restrictions simultaneously by bounding , on the one hand , the atoms which are allowed to occur in the rule heads of the context and , on the other hand , the atoms which are allowed to occur in the rule bodies of the context . We introduce a general semantical characterization which includes known ones as SE-models ( for strong equivalence ) or UE-models ( for uniform equivalence ) as special cases . Moreover , we provide complexity bounds for the problem in question and sketch a possible implementation method . To appear in Theory and Practice of Logic Programming ( TPLP ) .
0712.1014	cs.DM	Characterization Of A Class Of Graphs Related To Pairs Of Disjoint Matchings	For a given graph consider a pair of disjoint matchings the union of which contains as many edges as possible . Furthermore , consider the relation of the cardinalities of a maximum matching and the largest matching in those pairs . It is known that this relation does not exceed 5/4 for any graph . We characterize the class of graphs for which this relation is precisely 5/4 . Our characterization implies that these graphs contain a spanning subgraph , every component of which is the minimal graph of this class .
