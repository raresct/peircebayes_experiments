0708.1211	cs.DM cs.NA	A Deterministic Sub-linear Time Sparse Fourier Algorithm via Non-adaptive Compressed Sensing Methods	We study the problem of estimating the best B term Fourier representation for a given frequency-sparse signal ( i.e. , vector ) $ \textbf { A } $ of length $ N \gg B $ . More explicitly , we investigate how to deterministically identify B of the largest magnitude frequencies of $ \hat { \textbf { A } } $ , and estimate their coefficients , in polynomial $ ( B , \log N ) $ time . Randomized sub-linear time algorithms which have a small ( controllable ) probability of failure for each processed signal exist for solving this problem . However , for failure intolerant applications such as those involving mission-critical hardware designed to process many signals over a long lifetime , deterministic algorithms with no probability of failure are highly desirable . In this paper we build on the deterministic Compressed Sensing results of Cormode and Muthukrishnan ( CM ) \cite { CMDetCS3 , CMDetCS1 , CMDetCS2 } in order to develop the first known deterministic sub-linear time sparse Fourier Transform algorithm suitable for failure intolerant applications . Furthermore , in the process of developing our new Fourier algorithm , we present a simplified deterministic Compressed Sensing algorithm which improves on CM 's algebraic compressibility results while simultaneously maintaining their results concerning exponential decay .
0708.1242	cs.LG	Cost-minimising strategies for data labelling : optimal stopping and active learning	Supervised learning deals with the inference of a distribution over an output or label space $ \CY $ conditioned on points in an observation space $ \CX $ , given a training dataset $ D $ of pairs in $ \CX \times \CY $ . However , in a lot of applications of interest , acquisition of large amounts of observations is easy , while the process of generating labels is time-consuming or costly . One way to deal with this problem is { \em active } learning , where points to be labelled are selected with the aim of creating a model with better performance than that of an model trained on an equal number of randomly sampled points . In this paper , we instead propose to deal with the labelling cost directly : The learning goal is defined as the minimisation of a cost which is a function of the expected model performance and the total cost of the labels used . This allows the development of general strategies and specific algorithms for ( a ) optimal stopping , where the expected cost dictates whether label acquisition should continue ( b ) empirical evaluation , where the cost is used as a performance metric for a given combination of inference , stopping and sampling methods . Though the main focus of the paper is optimal stopping , we also aim to provide the background for further developments and discussion in the related field of active learning .
0708.1343	cs.IT math.IT math.RA	A Matrix Ring Description for Cyclic Convolutional Codes	In this paper , we study convolutional codes with a specific cyclic structure . By definition , these codes are left ideals in a certain skew polynomial ring . Using that the skew polynomial ring is isomorphic to a matrix ring we can describe the algebraic parameters of the codes in a more accessible way . We show that the existence of such codes with given algebraic parameters can be reduced to the solvability of a modified rook problem . It is our strong belief that the rook problem is always solvable , and we present solutions in particular cases .
