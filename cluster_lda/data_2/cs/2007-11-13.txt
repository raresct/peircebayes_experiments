0711.1986	cs.IT math.IT	Performance bounds and codes design criteria for channel decoding with a-priori information	In this article we focus on the problem of channel decoding in presence of a-priori information . In particular , assuming that the a-priori information reliability is not perfectly estimated at the receiver , we derive a novel analytical framework for evaluating the decoder 's performance . It is derived the important result that a `` good code '' , i.e. , a code which allows to fully exploit the potential benefit of a-priori information , must associate information sequences with high Hamming weights to codewords with low Hamming weights . Basing on the proposed analysis , we analyze the performance of convolutional codes , random codes , and turbo codes . Moreover , we consider the transmission of correlated binary sources from independent nodes , a problem which has several practical applications , e.g . in the case of sensor networks . In this context , we propose a very simple joint source-channel turbo decoding scheme where each decoder works by exploiting a-priori information given by the other decoder . In the case of block fading channels , it is shown that the inherent correlation between information signals provide a form of non-cooperative diversity , thus allowing joint source-channel decoding to outperform separation-based schemes .
0711.1993	cs.DM math.ST stat.TH	Entropy of capacities on lattices and set systems	We propose a definition for the entropy of capacities defined on lattices . Classical capacities are monotone set functions and can be seen as a generalization of probability measures . Capacities on lattices address the general case where the family of subsets is not necessarily the Boolean lattice of all subsets . Our definition encompasses the classical definition of Shannon for probability measures , as well as the entropy of Marichal defined for classical capacities . Some properties and examples are given .
0711.2010	cs.CC	A Polynomial Time Algorithm for Graph Isomorphism	Algorithms testing two graphs for isomorphism known as yet in computer science have exponential worst case complexity . In this paper we propose an algorithm that has polynomial complexity and constructively supplies the evidence that the graph isomorphism lies in P .
0711.2023	cs.LG cs.CL cs.IR	Empirical Evaluation of Four Tensor Decomposition Algorithms	Higher-order tensor decompositions are analogous to the familiar Singular Value Decomposition ( SVD ) , but they transcend the limitations of matrices ( second-order tensors ) . SVD is a powerful tool that has achieved impressive results in information retrieval , collaborative filtering , computational linguistics , computational vision , and other fields . However , SVD is limited to two-dimensional arrays of data ( two modes ) , and many potential applications have three or more modes , which require higher-order tensor decompositions . This paper evaluates four algorithms for higher-order tensor decomposition : Higher-Order Singular Value Decomposition ( HO-SVD ) , Higher-Order Orthogonal Iteration ( HOOI ) , Slice Projection ( SP ) , and Multislice Projection ( MP ) . We measure the time ( elapsed run time ) , space ( RAM and disk space requirements ) , and fit ( tensor reconstruction accuracy ) of the four algorithms , under a variety of conditions . We find that standard implementations of HO-SVD and HOOI do not scale up to larger tensors , due to increasing RAM requirements . We recommend HOOI for tensors that are small enough for the available RAM and MP for larger tensors .
0711.2050	cs.IT math.IT	Two Families of Quantum Codes Derived from Cyclic Codes	We characterize the affine-invariant maximal extended cyclic codes . Then by the CSS construction , we derive from these codes a family of pure quantum codes . Also for ordnq even , a new family of degenerate quantum stabilizer codes is derived from the classical duadic codes . This answer an open problem asked by Aly et al .
0711.2062	cs.DC	Autoregressive Time Series Forecasting of Computational Demand	We study the predictive power of autoregressive moving average models when forecasting demand in two shared computational networks , PlanetLab and Tycoon . Demand in these networks is very volatile , and predictive techniques to plan usage in advance can improve the performance obtained drastically . Our key finding is that a random walk predictor performs best for one-step-ahead forecasts , whereas ARIMA ( 1,1,0 ) and adaptive exponential smoothing models perform better for two and three-step-ahead forecasts . A Monte Carlo bootstrap test is proposed to evaluate the continuous prediction performance of different models with arbitrary confidence and statistical significance levels . Although the prediction results differ between the Tycoon and PlanetLab networks , we observe very similar overall statistical properties , such as volatility dynamics .
0711.2087	cs.DB cs.LO	Query Evaluation and Optimization in the Semantic Web	We address the problem of answering Web ontology queries efficiently . An ontology is formalized as a Deductive Ontology Base ( DOB ) , a deductive database that comprises the ontology 's inference axioms and facts . A cost-based query optimization technique for DOB is presented . A hybrid cost model is proposed to estimate the cost and cardinality of basic and inferred facts . Cardinality and cost of inferred facts are estimated using an adaptive sampling technique , while techniques of traditional relational cost models are used for estimating the cost of basic facts and conjunctive ontology queries . Finally , we implement a dynamic-programming optimization algorithm to identify query evaluation plans that minimize the number of intermediate inferred facts . We modeled a subset of the Web ontology language OWL Lite as a DOB , and performed an experimental study to analyze the predictive capacity of our cost model and the benefits of the query optimization technique . Our study has been conducted over synthetic and real-world OWL ontologies , and shows that the techniques are accurate and improve query performance . To appear in Theory and Practice of Logic Programming ( TPLP ) .
0711.2102	cs.IT math.IT	Patterns of i.i.d . Sequences and Their Entropy - Part II : Bounds for Some Distributions	A pattern of a sequence is a sequence of integer indices with each index describing the order of first occurrence of the respective symbol in the original sequence . In a recent paper , tight general bounds on the block entropy of patterns of sequences generated by independent and identically distributed ( i.i.d . ) sources were derived . In this paper , precise approximations are provided for the pattern block entropies for patterns of sequences generated by i.i.d . uniform and monotonic distributions , including distributions over the integers , and the geometric distribution . Numerical bounds on the pattern block entropies of these distributions are provided even for very short blocks . Tight bounds are obtained even for distributions that have infinite i.i.d . entropy rates . The approximations are obtained using general bounds and their derivation techniques . Conditional index entropy is also studied for distributions over smaller alphabets .
0711.2104	cs.IT cs.CV math.IT math.PR	On the Information Rates of the Plenoptic Function	The { \it plenoptic function } ( Adelson and Bergen , 91 ) describes the visual information available to an observer at any point in space and time . Samples of the plenoptic function ( POF ) are seen in video and in general visual content , and represent large amounts of information . In this paper we propose a stochastic model to study the compression limits of the plenoptic function . In the proposed framework , we isolate the two fundamental sources of information in the POF : the one representing the camera motion and the other representing the information complexity of the `` reality '' being acquired and transmitted . The sources of information are combined , generating a stochastic process that we study in detail . We first propose a model for ensembles of realities that do not change over time . The proposed model is simple in that it enables us to derive precise coding bounds in the information-theoretic sense that are sharp in a number of cases of practical interest . For this simple case of static realities and camera motion , our results indicate that coding practice is in accordance with optimal coding from an information-theoretic standpoint . The model is further extended to account for visual realities that change over time . We derive bounds on the lossless and lossy information rates for this dynamic reality model , stating conditions under which the bounds are tight . Examples with synthetic sources suggest that in the presence of scene dynamics , simple hybrid coding using motion/displacement estimation with DPCM performs considerably suboptimally relative to the true rate-distortion bound .
