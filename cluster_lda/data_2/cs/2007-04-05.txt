0704.0730	cs.PF cs.NI	Revisiting the Issues On Netflow Sample and Export Performance	The high volume of packets and packet rates of traffic on some router links makes it exceedingly difficult for routers to examine every packet in order to keep detailed statistics about the traffic which is traversing the router . Sampling is commonly applied on routers in order to limit the load incurred by the collection of information that the router has to undertake when evaluating flow information for monitoring purposes . The sampling process in nearly all cases is a deterministic process of choosing 1 in every N packets on a per-interface basis , and then forming the flow statistics based on the collected sampled statistics . Even though this sampling may not be significant for some statistics , such as packet rate , others can be severely distorted . However , it is important to consider the sampling techniques and their relative accuracy when applied to different traffic patterns . The main disadvantage of sampling is the loss of accuracy in the collected trace when compared to the original traffic stream . To date there has not been a detailed analysis of the impact of sampling at a router in various traffic profiles and flow criteria . In this paper , we assess the performance of the sampling process as used in NetFlow in detail , and we discuss some techniques for the compensation of loss of monitoring detail .
0704.0788	cs.DS cs.PF	Optimal Synthesis of Multiple Algorithms	In this paper we give a definition of `` algorithm , '' `` finite algorithm , '' '' equivalent algorithms , '' and what it means for a single algorithm to dominate a set of algorithms . We define a derived algorithm which may have a smaller mean execution time than any of its component algorithms . We give an explicit expression for the mean execution time ( when it exists ) of the derived algorithm . We give several illustrative examples of derived algorithms with two component algorithms . We include mean execution time solutions for two-algorithm processors whose joint density of execution times are of several general forms . For the case in which the joint density for a two-algorithm processor is a step function , we give a maximum-likelihood estimation scheme with which to analyze empirical processing time data .
0704.0802	cs.IT math.IT	Hybrid-ARQ in Multihop Networks with Opportunistic Relay Selection	This paper develops a contention-based opportunistic feedback technique towards relay selection in a dense wireless network . This technique enables the forwarding of additional parity information from the selected relay to the destination . For a given network , the effects of varying key parameters such as the feedback probability are presented and discussed . A primary advantage of the proposed technique is that relay selection can be performed in a distributed way . Simulation results find its performance to closely match that of centralized schemes that utilize GPS information , unlike the proposed method . The proposed relay selection method is also found to achieve throughput gains over a point-to-point transmission strategy .
0704.0805	cs.IT math.IT	Opportunistic Relay Selection with Limited Feedback	It has been shown that a decentralized relay selection protocol based on opportunistic feedback from the relays yields good throughput performance in dense wireless networks . This selection strategy supports a hybrid-ARQ transmission approach where relays forward parity information to the destination in the event of a decoding error . Such an approach , however , suffers a loss compared to centralized strategies that select relays with the best channel gain to the destination . This paper closes the performance gap by adding another level of channel feedback to the decentralized relay selection problem . It is demonstrated that only one additional bit of feedback is necessary for good throughput performance . The performance impact of varying key parameters such as the number of relays and the channel feedback threshold is discussed . An accompanying bit error rate analysis demonstrates the importance of relay selection .
0704.0831	cs.IT math.IT	On packet lengths and overhead for random linear coding over the erasure channel	We assess the practicality of random network coding by illuminating the issue of overhead and considering it in conjunction with increasingly long packets sent over the erasure channel . We show that the transmission of increasingly long packets , consisting of either of an increasing number of symbols per packet or an increasing symbol alphabet size , results in a data rate approaching zero over the erasure channel . This result is due to an erasure probability that increases with packet length . Numerical results for a particular modulation scheme demonstrate a data rate of approximately zero for a large , but finite-length packet . Our results suggest a reduction in the performance gains offered by random network coding .
0704.0834	cs.DS	P-adic arithmetic coding	A new incremental algorithm for data compression is presented . For a sequence of input symbols algorithm incrementally constructs a p-adic integer number as an output . Decoding process starts with less significant part of a p-adic integer and incrementally reconstructs a sequence of input symbols . Algorithm is based on certain features of p-adic numbers and p-adic norm . p-adic coding algorithm may be considered as of generalization a popular compression technique - arithmetic coding algorithms . It is shown that for p = 2 the algorithm works as integer variant of arithmetic coding ; for a special class of models it gives exactly the same codes as Huffman 's algorithm , for another special model and a specific alphabet it gives Golomb-Rice codes .
0704.0838	cs.IT math.IT	Universal Source Coding for Monotonic and Fast Decaying Monotonic Distributions	We study universal compression of sequences generated by monotonic distributions . We show that for a monotonic distribution over an alphabet of size $ k $ , each probability parameter costs essentially $ 0.5 \log ( n/k^3 ) $ bits , where $ n $ is the coded sequence length , as long as $ k = o ( n^ { 1/3 } ) $ . Otherwise , for $ k = O ( n ) $ , the total average sequence redundancy is $ O ( n^ { 1/3+\epsilon } ) $ bits overall . We then show that there exists a sub-class of monotonic distributions over infinite alphabets for which redundancy of $ O ( n^ { 1/3+\epsilon } ) $ bits overall is still achievable . This class contains fast decaying distributions , including many distributions over the integers and geometric distributions . For some slower decays , including other distributions over the integers , redundancy of $ o ( n ) $ bits overall is achievable , where a method to compute specific redundancy rates for such distributions is derived . The results are specifically true for finite entropy monotonic distributions . Finally , we study individual sequence redundancy behavior assuming a sequence is governed by a monotonic distribution . We show that for sequences whose empirical distributions are monotonic , individual redundancy bounds similar to those in the average case can be obtained . However , even if the monotonicity in the empirical distribution is violated , diminishing per symbol individual sequence redundancies with respect to the monotonic maximum likelihood description length may still be achievable .
