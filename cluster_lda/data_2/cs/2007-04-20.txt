0704.2651	cs.IT math.IT	Opportunistic Communications in an Orthogonal Multiaccess Relay Channel	The problem of resource allocation is studied for a two-user fading orthogonal multiaccess relay channel ( MARC ) where both users ( sources ) communicate with a destination in the presence of a relay . A half-duplex relay is considered that transmits on a channel orthogonal to that used by the sources . The instantaneous fading state between every transmit-receive pair in this network is assumed to be known at both the transmitter and receiver . Under an average power constraint at each source and the relay , the sum-rate for the achievable strategy of decode-and-forward ( DF ) is maximized over all power allocations ( policies ) at the sources and relay . It is shown that the sum-rate maximizing policy exploits the multiuser fading diversity to reveal the optimality of opportunistic channel use by each user . A geometric interpretation of the optimal power policy is also presented .
0704.2659	cs.IT math.IT	Minimum Expected Distortion in Gaussian Layered Broadcast Coding with Successive Refinement	A transmitter without channel state information ( CSI ) wishes to send a delay-limited Gaussian source over a slowly fading channel . The source is coded in superimposed layers , with each layer successively refining the description in the previous one . The receiver decodes the layers that are supported by the channel realization and reconstructs the source up to a distortion . In the limit of a continuum of infinite layers , the optimal power distribution that minimizes the expected distortion is given by the solution to a set of linear differential equations in terms of the density of the fading distribution . In the optimal power distribution , as SNR increases , the allocation over the higher layers remains unchanged ; rather the extra power is allocated towards the lower layers . On the other hand , as the bandwidth ratio b ( channel uses per source symbol ) tends to zero , the power distribution that minimizes expected distortion converges to the power distribution that maximizes expected capacity . While expected distortion can be improved by acquiring CSI at the transmitter ( CSIT ) or by increasing diversity from the realization of independent fading paths , at high SNR the performance benefit from diversity exceeds that from CSIT , especially when b is large .
0704.2668	cs.LG	Supervised Feature Selection via Dependence Estimation	We introduce a framework for filtering features that employs the Hilbert-Schmidt Independence Criterion ( HSIC ) as a measure of dependence between the features and the labels . The key idea is that good features should maximise such dependence . Feature selection for various supervised learning problems ( including classification and regression ) is unified under this framework , and the solutions can be approximated using a backward-elimination algorithm . We demonstrate the usefulness of our method on both artificial and real world datasets .
0704.2680	cs.IT math.IT	A Channel that Heats Up	Motivated by on-chip communication , a channel model is proposed where the variance of the additive noise depends on the weighted sum of the past channel input powers . For this channel , an expression for the capacity per unit cost is derived , and it is shown that the expression holds also in the presence of feedback .
0704.2725	cs.NE	Exploiting Heavy Tails in Training Times of Multilayer Perceptrons : A Case Study with the UCI Thyroid Disease Database	The random initialization of weights of a multilayer perceptron makes it possible to model its training process as a Las Vegas algorithm , i.e . a randomized algorithm which stops when some required training error is obtained , and whose execution time is a random variable . This modeling is used to perform a case study on a well-known pattern recognition benchmark : the UCI Thyroid Disease Database . Empirical evidence is presented of the training time probability distribution exhibiting a heavy tail behavior , meaning a big probability mass of long executions . This fact is exploited to reduce the training time cost by applying two simple restart strategies . The first assumes full knowledge of the distribution yielding a 40 % cut down in expected time with respect to the training without restarts . The second , assumes null knowledge , yielding a reduction ranging from 9 % to 23 % .
0704.2778	cs.IT math.IT	Random Access Broadcast : Stability and Throughput Analysis	A wireless network in which packets are broadcast to a group of receivers through use of a random access protocol is considered in this work . The relation to previous work on networks of interacting queues is discussed and subsequently , the stability and throughput regions of the system are analyzed and presented . A simple network of two source nodes and two destination nodes is considered first . The broadcast service process is analyzed assuming a channel that allows for packet capture and multipacket reception . In this small network , the stability and throughput regions are observed to coincide . The same problem for a network with N sources and M destinations is considered next . The channel model is simplified in that multipacket reception is no longer permitted . Bounds on the stability region are developed using the concept of stability rank and the throughput region of the system is compared to the bounds . Our results show that as the number of destination nodes increases , the stability and throughput regions diminish . Additionally , a previous conjecture that the stability and throughput regions coincide for a network of arbitrarily many sources is supported for a broadcast scenario by the results presented in this work .
0704.2779	cs.CC cs.GT	The Complexity of Simple Stochastic Games	In this paper we survey the computational time complexity of assorted simple stochastic game problems , and we give an overview of the best known algorithms associated with each problem .
0704.2786	cs.IT math.IT	Writing on Dirty Paper with Resizing and its Application to Quasi-Static Fading Broadcast Channels	This paper studies a variant of the classical problem of `` writing on dirty paper '' in which the sum of the input and the interference , or dirt , is multiplied by a random variable that models resizing , known to the decoder but not to the encoder . The achievable rate of Costa 's dirty paper coding ( DPC ) scheme is calculated and compared to the case of the decoder 's also knowing the dirt . In the ergodic case , the corresponding rate loss vanishes asymptotically in the limits of both high and low signal-to-noise ratio ( SNR ) , and is small at all finite SNR for typical distributions like Rayleigh , Rician , and Nakagami . In the quasi-static case , the DPC scheme is lossless at all SNR in terms of outage probability . Quasi-static fading broadcast channels ( BC ) without transmit channel state information ( CSI ) are investigated as an application of the robustness properties . It is shown that the DPC scheme leads to an outage achievable rate region that strictly dominates that of time division .
