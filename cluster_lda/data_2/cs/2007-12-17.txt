0712.2567	cs.DM	On Lower Bound for W ( K_ { 2n } )	The lower bound W ( K_ { 2n } ) > =3n-2 is proved for the greatest possible number of colors in an interval edge coloring of the complete graph K_ { 2n } .
0712.2585	cs.DM	Interval Edge Colourings of Complete Graphs and n-cubes	For complete graphs and n-cubes bounds are found for the possible number of colours in an interval edge colourings .
0712.2587	cs.IT math.IT	Maximum-Likelihood Priority-First Search Decodable Codes for Combined Channel Estimation and Error Protection	The code that combines channel estimation and error protection has received general attention recently , and has been considered a promising methodology to compensate multi-path fading effect . It has been shown by simulations that such code design can considerably improve the system performance over the conventional design with separate channel estimation and error protection modules under the same code rate . Nevertheless , the major obstacle that prevents from the practice of the codes is that the existing codes are mostly searched by computers , and hence exhibit no good structure for efficient decoding . Hence , the time-consuming exhaustive search becomes the only decoding choice , and the decoding complexity increases dramatically with the codeword length . In this paper , by optimizing the signal-tonoise ratio , we found a systematic construction for the codes for combined channel estimation and error protection , and confirmed its equivalence in performance to the computer-searched codes by simulations . Moreover , the structural codes that we construct by rules can now be maximum-likelihoodly decodable in terms of a newly derived recursive metric for use of the priority-first search decoding algorithm . Thus , the decoding complexity reduces significantly when compared with that of the exhaustive decoder . The extension code design for fast-fading channels is also presented . Simulations conclude that our constructed extension code is robust in performance even if the coherent period is shorter than the codeword length .
0712.2630	cs.NE cs.PL	Evolving XSLT stylesheets	This paper introduces a procedure based on genetic programming to evolve XSLT programs ( usually called stylesheets or logicsheets ) . XSLT is a general purpose , document-oriented functional language , generally used to transform XML documents ( or , in general , solve any problem that can be coded as an XML document ) . The proposed solution uses a tree representation for the stylesheets as well as diverse specific operators in order to obtain , in the studied cases and a reasonable time , a XSLT stylesheet that performs the transformation . Several types of representation have been compared , resulting in different performance and degree of success .
0712.2638	cs.CG math.AT	Towards Persistence-Based Reconstruction in Euclidean Spaces	Manifold reconstruction has been extensively studied for the last decade or so , especially in two and three dimensions . Recently , significant improvements were made in higher dimensions , leading to new methods to reconstruct large classes of compact subsets of Euclidean space $ \R^d $ . However , the complexities of these methods scale up exponentially with d , which makes them impractical in medium or high dimensions , even for handling low-dimensional submanifolds . In this paper , we introduce a novel approach that stands in-between classical reconstruction and topological estimation , and whose complexity scales up with the intrinsic dimension of the data . Specifically , when the data points are sufficiently densely sampled from a smooth $ m $ -submanifold of $ \R^d $ , our method retrieves the homology of the submanifold in time at most $ c ( m ) n^5 $ , where $ n $ is the size of the input and $ c ( m ) $ is a constant depending solely on $ m $ . It can also provably well handle a wide range of compact subsets of $ \R^d $ , though with worse complexities . Along the way to proving the correctness of our algorithm , we obtain new results on \v { C } ech , Rips , and witness complex filtrations in Euclidean spaces .
0712.2640	cs.AR cs.DM cs.IT math.IT	Optimal Memoryless Encoding for Low Power Off-Chip Data Buses	Off-chip buses account for a significant portion of the total system power consumed in embedded systems . Bus encoding schemes have been proposed to minimize power dissipation , but none has been demonstrated to be optimal with respect to any measure . In this paper , we give the first provably optimal and explicit ( polynomial-time constructible ) families of memoryless codes for minimizing bit transitions in off-chip buses . Our results imply that having access to a clock does not make a memoryless encoding scheme that minimizes bit transitions more powerful .
0712.2644	cs.GT cs.CC	Automata-based Adaptive Behavior for Economical Modelling Using Game Theory	In this chapter , we deal with some specific domains of applications to game theory . This is one of the major class of models in the new approaches of modelling in the economic domain . For that , we use genetic automata which allow to build adaptive strategies for the players . We explain how the automata-based formalism proposed - matrix representation of automata with multiplicities - allows to define semi-distance between the strategy behaviors . With that tools , we are able to generate an automatic processus to compute emergent systems of entities whose behaviors are represented by these genetic automata .
0712.2661	cs.DM cs.DS	Algorithms for Generating Convex Sets in Acyclic Digraphs	A set $ X $ of vertices of an acyclic digraph $ D $ is convex if $ X\neq \emptyset $ and there is no directed path between vertices of $ X $ which contains a vertex not in $ X $ . A set $ X $ is connected if $ X\neq \emptyset $ and the underlying undirected graph of the subgraph of $ D $ induced by $ X $ is connected . Connected convex sets and convex sets of acyclic digraphs are of interest in the area of modern embedded processor technology . We construct an algorithm $ \cal A $ for enumeration of all connected convex sets of an acyclic digraph $ D $ of order $ n $ . The time complexity of $ \cal A $ is $ O ( n\cdot cc ( D ) ) $ , where $ cc ( D ) $ is the number of connected convex sets in $ D $ . We also give an optimal algorithm for enumeration of all ( not just connected ) convex sets of an acyclic digraph $ D $ of order $ n $ . In computational experiments we demonstrate that our algorithms outperform the best algorithms in the literature . Using the same approach as for $ \cal A $ , we design an algorithm for generating all connected sets of a connected undirected graph $ G $ . The complexity of the algorithm is $ O ( n\cdot c ( G ) ) , $ where $ n $ is the order of $ G $ and $ c ( G ) $ is the number of connected sets of $ G. $ The previously reported algorithm for connected set enumeration is of running time $ O ( mn\cdot c ( G ) ) $ , where $ m $ is the number of edges in $ G. $
0712.2678	cs.DM	Convex sets in acyclic digraphs	A non-empty set $ X $ of vertices of an acyclic digraph is called connected if the underlying undirected graph induced by $ X $ is connected and it is called convex if no two vertices of $ X $ are connected by a directed path in which some vertices are not in $ X $ . The set of convex sets ( connected convex sets ) of an acyclic digraph $ D $ is denoted by $ \sco ( D ) $ ( $ \scc ( D ) $ ) and its size by $ \co ( D ) $ ( $ \cc ( D ) $ ) . Gutin , Johnstone , Reddington , Scott , Soleimanfallah , and Yeo ( Proc . ACiD'07 ) conjectured that the sum of the sizes of all ( connected ) convex sets in $ D $ equals $ \Theta ( n \cdot \co ( D ) ) $ ( $ \Theta ( n \cdot \cc ( D ) ) $ ) where $ n $ is the order of $ D $ . In this paper we exhibit a family of connected acyclic digraphs with $ \sum_ { C\in \sco ( D ) } |C| = o ( n\cdot \co ( D ) ) $ and $ \sum_ { C\in \scc ( D ) } |C| = o ( n\cdot \cc ( D ) ) $ . We also show that the number of connected convex sets of order $ k $ in any connected acyclic digraph of order $ n $ is at least $ n-k+1 $ . This is a strengthening of a theorem by Gutin and Yeo .
0712.2682	cs.DS stat.ML	An Approximation Ratio for Biclustering	The problem of biclustering consists of the simultaneous clustering of rows and columns of a matrix such that each of the submatrices induced by a pair of row and column clusters is as uniform as possible . In this paper we approximate the optimal biclustering by applying one-way clustering algorithms independently on the rows and on the columns of the input matrix . We show that such a solution yields a worst-case approximation ratio of 1+sqrt ( 2 ) under L1-norm for 0-1 valued matrices , and of 2 under L2-norm for real valued matrices .
0712.2737	cs.PL cs.SE	Experiments with a Convex Polyhedral Analysis Tool for Logic Programs	Convex polyhedral abstractions of logic programs have been found very useful in deriving numeric relationships between program arguments in order to prove program properties and in other areas such as termination and complexity analysis . We present a tool for constructing polyhedral analyses of ( constraint ) logic programs . The aim of the tool is to make available , with a convenient interface , state-of-the-art techniques for polyhedral analysis such as delayed widening , narrowing , `` widening up-to '' , and enhanced automatic selection of widening points . The tool is accessible on the web , permits user programs to be uploaded and analysed , and is integrated with related program transformations such as size abstractions and query-answer transformation . We then report some experiments using the tool , showing how it can be conveniently used to analyse transition systems arising from models of embedded systems , and an emulator for a PIC microcontroller which is used for example in wearable computing systems . We discuss issues including scalability , tradeoffs of precision and computation time , and other program transformations that can enhance the results of analysis .
0712.2773	cs.DB cs.DC cs.PF	Middleware-based Database Replication : The Gaps between Theory and Practice	The need for high availability and performance in data management systems has been fueling a long running interest in database replication from both academia and industry . However , academic groups often attack replication problems in isolation , overlooking the need for completeness in their solutions , while commercial teams take a holistic approach that often misses opportunities for fundamental innovation . This has created over time a gap between academic research and industrial practice . This paper aims to characterize the gap along three axes : performance , availability , and administration . We build on our own experience developing and deploying replication systems in commercial and academic settings , as well as on a large body of prior related work . We sift through representative examples from the last decade of open-source , academic , and commercial database replication systems and combine this material with case studies from real systems deployed at Fortune 500 customers . We propose two agendas , one for academic research and one for industrial R & D , which we believe can bridge the gap within 5-10 years . This way , we hope to both motivate and help researchers in making the theory and practice of middleware-based database replication more relevant to each other .
0712.2789	cs.CE cs.NA	Trading in Risk Dimensions ( TRD )	Previous work , mostly published , developed two-shell recursive trading systems . An inner-shell of Canonical Momenta Indicators ( CMI ) is adaptively fit to incoming market data . A parameterized trading-rule outer-shell uses the global optimization code Adaptive Simulated Annealing ( ASA ) to fit the trading system to historical data . A simple fitting algorithm , usually not requiring ASA , is used for the inner-shell fit . An additional risk-management middle-shell has been added to create a three-shell recursive optimization/sampling/fitting algorithm . Portfolio-level distributions of copula-transformed multivariate distributions ( with constituent markets possessing different marginal distributions in returns space ) are generated by Monte Carlo samplings . ASA is used to importance-sample weightings of these markets . The core code , Trading in Risk Dimensions ( TRD ) , processes Training and Testing trading systems on historical data , and consistently interacts with RealTime trading platforms at minute resolutions , but this scale can be modified . This approach transforms constituent probability distributions into a common space where it makes sense to develop correlations to further develop probability distributions and risk/uncertainty analyses of the full portfolio . ASA is used for importance-sampling these distributions and for optimizing system parameters .
0712.2857	cs.IT cs.DM math.CO math.IT	Single-Exclusion Number and the Stopping Redundancy of MDS Codes	For a linear block code C , its stopping redundancy is defined as the smallest number of check nodes in a Tanner graph for C , such that there exist no stopping sets of size smaller than the minimum distance of C. Schwartz and Vardy conjectured that the stopping redundancy of an MDS code should only depend on its length and minimum distance . We define the ( n , t ) -single-exclusion number , S ( n , t ) as the smallest number of t-subsets of an n-set , such that for each i-subset of the n-set , i=1 , ... , t+1 , there exists a t-subset that contains all but one element of the i-subset . New upper bounds on the single-exclusion number are obtained via probabilistic methods , recurrent inequalities , as well as explicit constructions . The new bounds are used to better understand the stopping redundancy of MDS codes . In particular , it is shown that for [ n , k=n-d+1 , d ] MDS codes , as n goes to infinity , the stopping redundancy is asymptotic to S ( n , d-2 ) , if d=o ( \sqrt { n } ) , or if k=o ( \sqrt { n } ) and k goes to infinity , thus giving partial confirmation of the Schwartz-Vardy conjecture in the asymptotic sense .
0712.2869	cs.LG	Density estimation in linear time	We consider the problem of choosing a density estimate from a set of distributions F , minimizing the L1-distance to an unknown distribution ( Devroye , Lugosi 2001 ) . Devroye and Lugosi analyze two algorithms for the problem : Scheffe tournament winner and minimum distance estimate . The Scheffe tournament estimate requires fewer computations than the minimum distance estimate , but has strictly weaker guarantees than the latter . We focus on the computational aspect of density estimation . We present two algorithms , both with the same guarantee as the minimum distance estimate . The first one , a modification of the minimum distance estimate , uses the same number ( quadratic in |F| ) of computations as the Scheffe tournament . The second one , called `` efficient minimum loss-weight estimate , '' uses only a linear number of computations , assuming that F is preprocessed . We also give examples showing that the guarantees of the algorithms can not be improved and explore randomized algorithms for density estimation .
0712.2870	cs.IT cs.CV math.IT	The source coding game with a cheating switcher	Motivated by the lossy compression of an active-vision video stream , we consider the problem of finding the rate-distortion function of an arbitrarily varying source ( AVS ) composed of a finite number of subsources with known distributions . Berger 's paper `The Source Coding Game ' , \emph { IEEE Trans . Inform . Theory } , 1971 , solves this problem under the condition that the adversary is allowed only strictly causal access to the subsource realizations . We consider the case when the adversary has access to the subsource realizations non-causally . Using the type-covering lemma , this new rate-distortion function is determined to be the maximum of the IID rate-distortion function over a set of source distributions attainable by the adversary . We then extend the results to allow for partial or noisy observations of subsource realizations . We further explore the model by attempting to find the rate-distortion function when the adversary is actually helpful . Finally , a bound is developed on the uniform continuity of the IID rate-distortion function for finite-alphabet sources . The bound is used to give a sufficient number of distributions that need to be sampled to compute the rate-distortion function of an AVS to within a certain accuracy . The bound is also used to give a rate of convergence for the estimate of the rate-distortion function for an unknown IID finite-alphabet source .
0712.2872	cs.IT math.IT	Low SNR Capacity of Noncoherent Fading Channels	Discrete-time Rayleigh fading single-input single-output ( SISO ) and multiple-input multiple-output ( MIMO ) channels are considered , with no channel state information at the transmitter or the receiver . The fading is assumed to be stationary and correlated in time , but independent from antenna to antenna . Peak-power and average-power constraints are imposed on the transmit antennas . For MIMO channels , these constraints are either imposed on the sum over antennas , or on each individual antenna . For SISO channels and MIMO channels with sum power constraints , the asymptotic capacity as the peak signal-to-noise ratio tends to zero is identified ; for MIMO channels with individual power constraints , this asymptotic capacity is obtained for a class of channels called transmit separable channels . The results for MIMO channels with individual power constraints are carried over to SISO channels with delay spread ( i.e . frequency selective fading ) .
