0706.2035	cs.CC	Critique of Feinstein 's Proof that P is not Equal to NP	We examine a proof by Craig Alan Feinstein that P is not equal to NP . We present counterexamples to claims made in his paper and expose a flaw in the methodology he uses to make his assertions . The fault in his argument is the incorrect use of reduction . Feinstein makes incorrect assumptions about the complexity of a problem based on the fact that there is a more complex problem that can be used to solve it . His paper introduces the terminology `` imaginary processor '' to describe how it is possible to beat the brute force reduction he offers to solve the Subset-Sum problem . The claims made in the paper would not be validly established even were imaginary processors to exist .
0706.2069	cs.DC	Building Portable Thread Schedulers for Hierarchical Multiprocessors : the BubbleSched Framework	Exploiting full computational power of current more and more hierarchical multiprocessor machines requires a very careful distribution of threads and data among the underlying non-uniform architecture . Unfortunately , most operating systems only provide a poor scheduling API that does not allow applications to transmit valuable scheduling hints to the system . In a previous paper , we showed that using a bubble-based thread scheduler can significantly improve applications ' performance in a portable way . However , since multithreaded applications have various scheduling requirements , there is no universal scheduler that could meet all these needs . In this paper , we present a framework that allows scheduling experts to implement and experiment with customized thread schedulers . It provides a powerful API for dynamically distributing bubbles among the machine in a high-level , portable , and efficient way . Several examples show how experts can then develop , debug and tune their own portable bubble schedulers .
0706.2073	cs.PL	An Efficient OpenMP Runtime System for Hierarchical Arch	Exploiting the full computational power of always deeper hierarchical multiprocessor machines requires a very careful distribution of threads and data among the underlying non-uniform architecture . The emergence of multi-core chips and NUMA machines makes it important to minimize the number of remote memory accesses , to favor cache affinities , and to guarantee fast completion of synchronization steps . By using the BubbleSched platform as a threading backend for the GOMP OpenMP compiler , we are able to easily transpose affinities of thread teams into scheduling hints using abstractions called bubbles . We then propose a scheduling strategy suited to nested OpenMP parallelism . The resulting preliminary performance evaluations show an important improvement of the speedup on a typical NAS OpenMP benchmark application .
0706.2076	cs.LO	A Finite Semantics of Simply-Typed Lambda Terms for Infinite Runs of < br > Automata	Model checking properties are often described by means of finite automata . Any particular such automaton divides the set of infinite trees into finitely many classes , according to which state has an infinite run . Building the full type hierarchy upon this interpretation of the base type gives a finite semantics for simply-typed lambda-trees . A calculus based on this semantics is proven sound and complete . In particular , for regular infinite lambda-trees it is decidable whether a given automaton has a run or not . As regular lambda-trees are precisely recursion schemes , this decidability result holds for arbitrary recursion schemes of arbitrary level , without any syntactical restriction .
0706.2146	cs.DC	Efficient Multidimensional Data Redistribution for Resizable Parallel Computations	Traditional parallel schedulers running on cluster supercomputers support only static scheduling , where the number of processors allocated to an application remains fixed throughout the execution of the job . This results in under-utilization of idle system resources thereby decreasing overall system throughput . In our research , we have developed a prototype framework called ReSHAPE , which supports dynamic resizing of parallel MPI applications executing on distributed memory platforms . The resizing library in ReSHAPE includes support for releasing and acquiring processors and efficiently redistributing application state to a new set of processors . In this paper , we derive an algorithm for redistributing two-dimensional block-cyclic arrays from $ P $ to $ Q $ processors , organized as 2-D processor grids . The algorithm ensures a contention-free communication schedule for data redistribution if $ P_r \leq Q_r $ and $ P_c \leq Q_c $ . In other cases , the algorithm implements circular row and column shifts on the communication schedule to minimize node contention .
0706.2153	cs.CG math.CA math.MG	Stability of boundary measures	We introduce the boundary measure at scale r of a compact subset of the n-dimensional Euclidean space . We show how it can be computed for point clouds and suggest these measures can be used for feature detection . The main contribution of this work is the proof a quantitative stability theorem for boundary measures using tools of convex analysis and geometric measure theory . As a corollary we obtain a stability result for Federer 's curvature measures of a compact , allowing to compute them from point-cloud approximations of the compact .
0706.2155	cs.DS cs.CC cs.DC	Dualheap Selection Algorithm : Efficient , Inherently Parallel and Somewhat Mysterious	An inherently parallel algorithm is proposed that efficiently performs selection : finding the K-th largest member of a set of N members . Selection is a common component of many more complex algorithms and therefore is a widely studied problem . Not much is new in the proposed dualheap selection algorithm : the heap data structure is from J.W.J.Williams , the bottom-up heap construction is from R.W . Floyd , and the concept of a two heap data structure is from J.W.J . Williams and D.E . Knuth . The algorithm 's novelty is limited to a few relatively minor implementation twists : 1 ) the two heaps are oriented with their roots at the partition values rather than at the minimum and maximum values , 2 ) the coding of one of the heaps ( the heap of smaller values ) employs negative indexing , and 3 ) the exchange phase of the algorithm is similar to a bottom-up heap construction , but navigates the heap with a post-order tree traversal . When run on a single processor , the dualheap selection algorithm's performance is competitive with quickselect with median estimation , a common variant of C.A.R . Hoare 's quicksort algorithm . When run on parallel processors , the dualheap selection algorithm is superior due to its subtasks that are easily partitioned and innately balanced .
