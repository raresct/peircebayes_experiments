0706.2549	q-bio.MN q-bio.QM	A statistical mechanics approach to reverse engineering : sparsity and biological priors on gene regulatory networks	The important task of determining the connectivity of gene networks , and at a more detailed level even the kind of interaction existing between genes , can nowadays be tackled by microarraylike technologies . Yet , there is still a large amount of unknowns with respect to the amount of data provided by a single microarray experiment , and therefore reliable gene network retrieval procedures must integrate all of the available biological knowledge , even if coming from different sources and of different nature . In this paper we present a reverse engineering algorithm able to reveal the underlying gene network by using time-series dataset on gene expressions considering the system response to different perturbations . The approach is able to determine the sparsity of the gene network , and to take into account possible { \it a priori } biological knowledge on it . The validity of the reverse engineering approach is highlighted through the deduction of the topology of several { \it simulated } gene networks , where we also discuss how the performance of the algorithm improves enlarging the amount of data or if any a priori knowledge is considered . We also apply the algorithm to experimental data on a nine gene network in { \it Escherichia coli
0706.2602	q-bio.NC	Effects of Hebbian learning on the dynamics and structure of random networks with inhibitory and excitatory neurons	The aim of the present paper is to study the effects of Hebbian learning in random recurrent neural networks with biological connectivity , i.e . sparse connections and separate populations of excitatory and inhibitory neurons . We furthermore consider that the neuron dynamics may occur at a ( shorter ) time scale than synaptic plasticity and consider the possibility of learning rules with passive forgetting . We show that the application of such Hebbian learning leads to drastic changes in the network dynamics and structure . In particular , the learning rule contracts the norm of the weight matrix and yields a rapid decay of the dynamics complexity and entropy . In other words , the network is rewired by Hebbian learning into a new synaptic structure that emerges with learning on the basis of the correlations that progressively build up between neurons . We also observe that , within this emerging structure , the strongest synapses organize as a small-world network . The second effect of the decay of the weight matrix spectral radius consists in a rapid contraction of the spectral radius of the Jacobian matrix . This drives the system through the `` edge of chaos '' where sensitivity to the input pattern is maximal . Taken together , this scenario is remarkably predicted by theoretical arguments derived from dynamical systems and graph theory .
